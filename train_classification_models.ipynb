{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "%matplotlib notebook \n",
    "\n",
    "# Import resources\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# dot dict for args\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/best-practices-for-preparing-and-augmenting-image-data-for-convolutional-neural-networks/\n",
    "def get_training_augmentation(input_size=224):\n",
    "    train_transform = [\n",
    "        \n",
    "        # 1. Get a random square crop of the image\n",
    "        # and rescale (preserve aspect ratio) to input size with random interpolation method\n",
    "        # REF: GoogLeNet (Inception) - Going Deeper with Convolutions, 2014\n",
    "        A.OneOf([\n",
    "            A.RandomResizedCrop(height=input_size, width=input_size, ratio=(1.0,1.0), interpolation=cv2.INTER_NEAREST),\n",
    "            A.RandomResizedCrop(height=input_size, width=input_size, ratio=(1.0,1.0), interpolation=cv2.INTER_LINEAR),\n",
    "            A.RandomResizedCrop(height=input_size, width=input_size, ratio=(1.0,1.0), interpolation=cv2.INTER_CUBIC),\n",
    "            A.RandomResizedCrop(height=input_size, width=input_size, ratio=(1.0,1.0), interpolation=cv2.INTER_AREA),\n",
    "            ], \n",
    "            p=1\n",
    "        ),\n",
    "        \n",
    "        # 2. random flipping / rotating\n",
    "        A.RandomRotate90(p=1),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "                \n",
    "        # 3. photometric distortions ()\n",
    "        # REF: GoogLeNet (Inception) - Going Deeper with Convolutions, 2014\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightness(p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomContrast(p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        \n",
    "        # 4. Add noise\n",
    "        A.IAAAdditiveGaussianNoise(p=0.33),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=1),\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.33,\n",
    "        ),\n",
    "                       \n",
    "    ]\n",
    "\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation(input_size=224):\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.SmallestMaxSize(256), \n",
    "        A.CenterCrop(256,256),\n",
    "        A.Resize(input_size,input_size),\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return torch.tensor(x.transpose(2, 0, 1).astype('float32'))\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: Amentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(datasets.folder.ImageFolder):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root, transform=None, target_transform=None, is_valid_file=None, preprocessing=None):\n",
    "        super(datasets.folder.ImageFolder, self).__init__(root, datasets.folder.default_loader,\n",
    "                                                          datasets.folder.IMG_EXTENSIONS,\n",
    "                                          transform=transform,\n",
    "                                          target_transform=target_transform,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "        self.preprocessing = preprocessing\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (sample, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        sample = cv2.imread(path)\n",
    "        sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(image = sample)['image']\n",
    "            \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing is not None:\n",
    "            sample = self.preprocessing(image=sample)['image']\n",
    "        \n",
    "            \n",
    "        return sample, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        \n",
    "        target = torch.tensor(target)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "                \n",
    "            target = torch.tensor(target)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg, top5.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        main_worker(args.gpu, ngpus_per_node, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "\n",
    "    if args.distributed:\n",
    "        if args.dist_url == \"env://\" and args.rank == -1:\n",
    "            args.rank = int(os.environ[\"RANK\"])\n",
    "        if args.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "    # create model\n",
    "    if args.pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "        if args.arch in list(models.__dict__.keys()):\n",
    "            model = models.__dict__[args.arch](pretrained=True)\n",
    "        elif args.arch in pretrainedmodels.model_names:\n",
    "            try:\n",
    "                model = pretrainedmodels.__dict__[args.arch](pretrained='imagenet')\n",
    "            except KeyError:\n",
    "                model = pretrainedmodels.__dict__[args.arch](pretrained='imagenet+5k')\n",
    "                \n",
    "        elif args.arch.startswith('efficientnet'):\n",
    "            model = EfficientNet.from_pretrained(args.arch)\n",
    "        else:\n",
    "            print('\\n\\nWARNING, CANNOT LOAD', args.arch, '\\n\\n')\n",
    "            \n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(args.arch))\n",
    "        if args.arch in list(models.__dict__.keys()):\n",
    "            model = models.__dict__[args.arch]()\n",
    "        elif args.arch in pretrainedmodels.model_names:\n",
    "            model = pretrainedmodels.__dict__[args.arch]()\n",
    "        elif args.arch.startswith('efficientnet'):\n",
    "            model = EfficientNet.from_name(args.arch)\n",
    "        else:\n",
    "            print('\\n\\nWARNING, CANNOT LOAD', args.arch, '\\n\\n')\n",
    "\n",
    "    if args.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "            model.features = torch.nn.DataParallel(model.features)\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "            else:\n",
    "                # Map model to be loaded to specified single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_acc1 = checkpoint['best_acc1']\n",
    "            if args.gpu is not None:\n",
    "                # best_acc1 may be from a checkpoint from a different GPU\n",
    "                best_acc1 = best_acc1.to(args.gpu)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(args.data, 'train')\n",
    "    valdir = os.path.join(args.data, 'val')\n",
    "\n",
    "    input_size = 299 if args.arch.startswith(\"inception\") else 224\n",
    "    try:\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(args.arch)  \n",
    "    except ValueError:\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(args.arch, pretrained='imagenet+5k') \n",
    "    \n",
    "    train_dataset = Dataset(\n",
    "        traindir,\n",
    "        transform=get_training_augmentation(input_size), \n",
    "        preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )\n",
    "\n",
    "    valid_dataset = Dataset(\n",
    "        valdir,\n",
    "        transform=get_validation_augmentation(input_size), \n",
    "        preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )\n",
    "\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        \n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    patience = 0\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1, acc5, val_loss = validate(val_loader, model, criterion, args)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "                and args.rank % ngpus_per_node == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'acc5': acc5,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'val_loss': val_losses,\n",
    "                'train_loss': train_losses\n",
    "            }, is_best)\n",
    "            \n",
    "        # Early stopping\n",
    "        if args.patience is not None:\n",
    "            patience = patience + 1 if not is_best else 0\n",
    "            if patience >= args.patience:\n",
    "                print('\\n\\nEarly stopping.  No improvement in %d epochs.\\n\\n' % patience)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models512 = ['resnet101', 'dpn92', 'se_resnet101', 'se_resnext50_32x4d', 'inceptionv4',\n",
    "             'efficientnet-b1', 'efficientnet-b2',\n",
    "             'vgg13_bn', 'vgg16_bn', 'densenet121', 'xception'] # more than 26M params\n",
    "models256 = ['resnet152', 'resnext101_32x8d', 'dpn98', 'dpn107', 'dpn131', 'se_resnet152', 'efficientnet-b3', \n",
    "             'efficientnet-b4', 'se_resnext101_32x4d' ,\n",
    "             'se_resnext101_32x4d', 'densenet169', 'densenet201', 'densenet161'] # more than 50M params\n",
    "models128 = ['senet154', 'inceptionresnetv2', 'efficientnet-b6', 'efficientnet-b7', 'efficientnet-b5'] # more than 100M params\n",
    "# Don't run, more than 200M params or no pretrained version\n",
    "models_no_run = ['resnext101_32x32d', 'resnext101_32x48d', 'efficientnet-b6', \n",
    "                 'efficientnet-b7', 'resnext101_32x16d', 'resnext101_32x32d',\n",
    "                'resnext101_32x48d', 'vgg16', 'vgg19', 'vgg19_bn', 'vgg13', 'vgg11'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "data_dir = r'./data/microscopy/data_v4/'\n",
    "architecture = 'se_resnet50'\n",
    "pretrained = True\n",
    "resume = ''\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "batch_size = 1024\n",
    "epochs = 90\n",
    "start_epoch = 0\n",
    "num_workers = 16\n",
    "\n",
    "args = dotdict({'data': data_dir,\n",
    "                'arch': architecture,\n",
    "               'workers': num_workers,\n",
    "               'epochs': epochs,\n",
    "               'start_epoch': start_epoch,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': learning_rate,\n",
    "               'learning_rate': learning_rate,\n",
    "               'momentum': momentum,\n",
    "               'weight_decay': weight_decay,\n",
    "               'print_freq': 10,\n",
    "               'resume': resume,\n",
    "               'pretrained': pretrained,\n",
    "               'evaluate': False,\n",
    "               'world_size': -1,\n",
    "               'rank': -1,\n",
    "               'gpu': None,\n",
    "               'multiprocessing_distributed': False,\n",
    "               'patience': None})\n",
    "\n",
    "for arch in smp.encoders.get_encoder_names()[45:]:\n",
    "    t0 = time.time()\n",
    "    best_acc1 = 0 # reset the best accuracy\n",
    "    args.arch = arch\n",
    "    \n",
    "    # set the batch size based on the number of model params\n",
    "    if arch in models512:\n",
    "        args.batch_size = 512\n",
    "    elif arch in models256:\n",
    "        args.batch_size = 256\n",
    "    elif arch in models128:\n",
    "        args.batch_size = 128\n",
    "    elif arch in models_no_run: #skip this architecture\n",
    "        print('\\n\\nSkipping', arch, '\\n\\n')\n",
    "        continue\n",
    "    else:\n",
    "        args.batch_size = 1024\n",
    "        \n",
    "    print('\\n\\nTraining', arch, 'with batch size', args.batch_size, '\\n\\n')\n",
    "    # train the model\n",
    "    main(args)\n",
    "    \n",
    "    #save the model\n",
    "    best_path = r'./model_best.pth.tar'\n",
    "    bm = torch.load(best_path)\n",
    "    dest_path = r'./{}_microscopy_epochs_{}_acc1_{:.3f}_acc5_{:.3f}.pth.tar'.format(\n",
    "        bm['arch'], bm['epoch'], bm['best_acc1'].item(), bm['acc5'].item())\n",
    "    shutil.copy(best_path, dest_path) \n",
    "    print(arch, 'took', round((time.time()-t0)/60, 2), 'minutes to train.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "data_dir = r'./data/microscopy/data_v4/'\n",
    "architecture = 'se_resnet50'\n",
    "pretrained = True\n",
    "resume = ''\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "batch_size = 1024\n",
    "epochs = 200\n",
    "start_epoch = 0\n",
    "num_workers = 16\n",
    "patience = 30 # early stopping patience\n",
    "\n",
    "args = dotdict({'data': data_dir,\n",
    "                'arch': architecture,\n",
    "               'workers': num_workers,\n",
    "               'epochs': epochs,\n",
    "               'start_epoch': start_epoch,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': learning_rate,\n",
    "               'learning_rate': learning_rate,\n",
    "               'momentum': momentum,\n",
    "               'weight_decay': weight_decay,\n",
    "               'print_freq': 10,\n",
    "               'resume': resume,\n",
    "               'pretrained': pretrained,\n",
    "               'evaluate': False,\n",
    "               'world_size': -1,\n",
    "               'rank': -1,\n",
    "               'gpu': None,\n",
    "               'multiprocessing_distributed': False,\n",
    "               'patience': patience})\n",
    "\n",
    "\n",
    "trained_models = [f for f in os.listdir() if f.endswith(\".tar\")]\n",
    "for f in trained_models:\n",
    "    if f.startswith('checkpoint') or f.startswith('model_best') or 'fromscratch' in f:\n",
    "        print('skipping {}'.format(f))\n",
    "        continue\n",
    "    epochs = int(f.split('epochs_')[1].split('_acc1_')[0])\n",
    "    if epochs < 81 or epochs > 90:\n",
    "        print('skipping {}'.format(f))\n",
    "        continue\n",
    "        \n",
    "    args.resume = f\n",
    "    \n",
    "    t0 = time.time()\n",
    "    best_acc1 = 0 # reset the best accuracy\n",
    "    arch = f.split('_microscopy_')[0]\n",
    "    args.arch = arch\n",
    "    \n",
    "    \n",
    "    # set the batch size based on the number of model params\n",
    "    if arch in models512:\n",
    "        args.batch_size = 512\n",
    "    elif arch in models256:\n",
    "        args.batch_size = 256\n",
    "    elif arch in models128:\n",
    "        args.batch_size = 128\n",
    "    elif arch in models_no_run: #skip this architecture\n",
    "        print('\\n\\nSkipping', arch, '\\n\\n')\n",
    "        continue\n",
    "    else:\n",
    "        args.batch_size = 1024\n",
    "        \n",
    "    print('\\n\\nTraining', arch, 'with batch size', args.batch_size, '\\n\\n')\n",
    "    # train the model\n",
    "    main(args)\n",
    "    \n",
    "    #save the model\n",
    "    best_path = r'./model_best.pth.tar'\n",
    "    bm = torch.load(best_path)\n",
    "    dest_path = r'./{}_microscopy_epochs_{}_acc1_{:.3f}_acc5_{:.3f}.pth.tar'.format(\n",
    "        bm['arch'], bm['epoch'], bm['best_acc1'].item(), bm['acc5'].item())\n",
    "    shutil.copy(best_path, dest_path) \n",
    "    print(arch, 'took', round((time.time()-t0)/60, 2), 'minutes to train.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train them all without pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_scratch_models = ['se_resnet50', 'se_resnext50_32x4d', 'efficientnet-b3', 'inceptionresnetv2', 'inceptionv4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "data_dir = r'./data/microscopy/data_v4/'\n",
    "architecture = 'se_resnet50'\n",
    "pretrained = True\n",
    "resume = ''\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "batch_size = 1024\n",
    "epochs = 500\n",
    "start_epoch = 0\n",
    "num_workers = 16\n",
    "patience = 30\n",
    "\n",
    "args = dotdict({'data': data_dir,\n",
    "                'arch': architecture,\n",
    "               'workers': num_workers,\n",
    "               'epochs': epochs,\n",
    "               'start_epoch': start_epoch,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': learning_rate,\n",
    "               'learning_rate': learning_rate,\n",
    "               'momentum': momentum,\n",
    "               'weight_decay': weight_decay,\n",
    "               'print_freq': 10,\n",
    "               'resume': resume,\n",
    "               'pretrained': False,\n",
    "               'evaluate': False,\n",
    "               'world_size': -1,\n",
    "               'rank': -1,\n",
    "               'gpu': None,\n",
    "               'multiprocessing_distributed': False,\n",
    "               'patience': patience})\n",
    "\n",
    "for arch in from_scratch_models[0:]:\n",
    "    t0 = time.time()\n",
    "    best_acc1 = 0 # reset the best accuracy\n",
    "    args.arch = arch\n",
    "    \n",
    "    # set the batch size based on the number of model params\n",
    "    if arch in models512:\n",
    "        args.batch_size = 512\n",
    "    elif arch in models256:\n",
    "        args.batch_size = 256\n",
    "    elif arch in models128:\n",
    "        args.batch_size = 128\n",
    "    elif arch in models_no_run: #skip this architecture\n",
    "        print('\\n\\nSkipping', arch, '\\n\\n')\n",
    "        continue\n",
    "    else:\n",
    "        args.batch_size = 1024\n",
    "        \n",
    "    print('\\n\\nTraining', arch, 'with batch size', args.batch_size, '\\n\\n')\n",
    "    # train the model\n",
    "    main(args)\n",
    "    \n",
    "    #save the model\n",
    "    best_path = r'./model_best.pth.tar'\n",
    "    bm = torch.load(best_path)\n",
    "    dest_path = r'./{}_microscopy_fromscratch_epochs_{}_acc1_{:.3f}_acc5_{:.3f}.pth.tar'.format(\n",
    "        bm['arch'], bm['epoch'], bm['best_acc1'].item(), bm['acc5'].item())\n",
    "    shutil.copy(best_path, dest_path) \n",
    "    print(arch, 'took', round((time.time()-t0)/60, 2), 'minutes to train.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = r'./resnet18_microscopy_epochs_75_acc1_81.185_acc5_96.926.pth.tar'\n",
    "bm = torch.load(best_path)\n",
    "plt.plot(range(len(bm['train_loss'])), bm['train_loss'])\n",
    "plt.plot(range(len(bm['val_loss'])), bm['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "best_path = r'./model_best.pth.tar'\n",
    "model = pretrainedmodels.__dict__[args.arch]()\n",
    "state_dict = torch.load(best_path)['state_dict']\n",
    "\n",
    "if list(state_dict.keys())[0].startswith('module'):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    state_dict = new_state_dict\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(architecture)  \n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "valid_dataset = Dataset(\n",
    "        valdir,\n",
    "        transform=get_validation_augmentation(), \n",
    "        preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1000)\n",
    "    valid_preds = get_all_preds(model, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlim((len(classes), -0.5))\n",
    "    plt.ylim((-0.5, len(classes)))\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(architecture+'.jpg')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(valid_dataset.targets, valid_preds.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, valid_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
