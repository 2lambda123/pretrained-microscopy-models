{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import segmentation_models_pytorch as smp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_module_from_state_dict(state_dict):\r\n",
    "    \"\"\"Removes 'module.' from nn.Parallel models.  \r\n",
    "    If module does not exist it just returns the state dict\"\"\"\r\n",
    "    if list(state_dict.keys())[0].startswith('module'):\r\n",
    "        new_state_dict = OrderedDict()\r\n",
    "        for k, v in state_dict.items():\r\n",
    "            name = k[7:] # remove `module.`\r\n",
    "            new_state_dict[name] = v           \r\n",
    "        return new_state_dict\r\n",
    "    elif list(state_dict.keys())[0].startswith('features.module'):\r\n",
    "        new_state_dict = OrderedDict()\r\n",
    "        for k, v in state_dict.items():\r\n",
    "            name = k[:9] + k[9+7:] # remove `module.`\r\n",
    "            if name.startswith('features.'):\r\n",
    "                new_state_dict[name] = v\r\n",
    "        return new_state_dict\r\n",
    "    else:\r\n",
    "        return state_dict\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_model(model_path):\r\n",
    "    model_data = torch.load(model_path)\r\n",
    "    #DEVICE = 'cuda'\r\n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    decoder = model_data['decoder']\r\n",
    "    encoder = model_data['encoder']\r\n",
    "    #class_values = best_model['class_values']\r\n",
    "    class_values = {'background': 0,\r\n",
    "                    'oxide': 1,\r\n",
    "                    'crack': 2}\r\n",
    "    activation = 'softmax2d' if len(class_values) > 1 else 'sigmoid' #'softmax2d' for multicalss segmentation\r\n",
    "    try:\r\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, 'imagenet')\r\n",
    "    except ValueError:\r\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(encoder, 'imagenet+5k')\r\n",
    "    model = getattr(smp, decoder)(encoder_name=encoder, \r\n",
    "                                          encoder_weights=None,\r\n",
    "                                          classes=len(class_values),\r\n",
    "                                          activation=activation)\r\n",
    "\r\n",
    "    model.load_state_dict(remove_module_from_state_dict(model_data['state_dict']))\r\n",
    "    model.eval()\r\n",
    "    return model, preprocessing_fn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# https://github.com/choosehappy/PytorchDigitalPathology\r\n",
    "def segmentation_models_inference(io, model, preprocessing_fn, device = None, batch_size = 8, patch_size = 512,\r\n",
    "                                  num_classes=3, probabilities=None):\r\n",
    "\r\n",
    "    # This will not output the first class and assumes that the first class is wherever the other classes are not!\r\n",
    "\r\n",
    "    io = preprocessing_fn(io)\r\n",
    "    io_shape_orig = np.array(io.shape)\r\n",
    "    stride_size = patch_size // 2\r\n",
    "    if device is None:\r\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    # add half the stride as padding around the image, so that we can crop it away later\r\n",
    "    io = np.pad(io, [(stride_size // 2, stride_size // 2), (stride_size // 2, stride_size // 2), (0, 0)],\r\n",
    "                mode=\"reflect\")\r\n",
    "\r\n",
    "    io_shape_wpad = np.array(io.shape)\r\n",
    "\r\n",
    "    # pad to match an exact multiple of unet patch size, otherwise last row/column are lost\r\n",
    "    npad0 = int(np.ceil(io_shape_wpad[0] / patch_size) * patch_size - io_shape_wpad[0])\r\n",
    "    npad1 = int(np.ceil(io_shape_wpad[1] / patch_size) * patch_size - io_shape_wpad[1])\r\n",
    "\r\n",
    "    io = np.pad(io, [(0, npad0), (0, npad1), (0, 0)], mode=\"constant\")\r\n",
    "\r\n",
    "    with warnings.catch_warnings():\r\n",
    "        warnings.simplefilter('ignore')\r\n",
    "        arr_out = sklearn.feature_extraction.image.extract_patches(io, (patch_size, patch_size, 3), stride_size)\r\n",
    "\r\n",
    "    arr_out_shape = arr_out.shape\r\n",
    "    arr_out = arr_out.reshape(-1, patch_size, patch_size, 3)\r\n",
    "\r\n",
    "    # in case we have a large network, lets cut the list of tiles into batches\r\n",
    "    output = np.zeros((0, num_classes, patch_size, patch_size))\r\n",
    "    for batch_arr in divide_batch(arr_out, batch_size):\r\n",
    "        arr_out_gpu = torch.from_numpy(batch_arr.transpose(0, 3, 1, 2).astype('float32')).to(device)\r\n",
    "\r\n",
    "        # ---- get results\r\n",
    "        output_batch = model.predict(arr_out_gpu)\r\n",
    "\r\n",
    "        # --- pull from GPU and append to rest of output\r\n",
    "        if probabilities is None:\r\n",
    "            output_batch = output_batch.detach().cpu().numpy().round()\r\n",
    "        else:\r\n",
    "            output_batch = output_batch.detach().cpu().numpy()\r\n",
    "\r\n",
    "        output = np.append(output, output_batch, axis=0)\r\n",
    "\r\n",
    "    output = output.transpose((0, 2, 3, 1))\r\n",
    "\r\n",
    "    # turn from a single list into a matrix of tiles\r\n",
    "    output = output.reshape(arr_out_shape[0], arr_out_shape[1], patch_size, patch_size, output.shape[3])\r\n",
    "\r\n",
    "    # remove the padding from each tile, we only keep the center\r\n",
    "    output = output[:, :, stride_size // 2:-stride_size // 2, stride_size // 2:-stride_size // 2, :]\r\n",
    "\r\n",
    "    # turn all the tiles into an image\r\n",
    "    output = np.concatenate(np.concatenate(output, 1), 1)\r\n",
    "\r\n",
    "    # incase there was extra padding to get a multiple of patch size, remove that as well\r\n",
    "    output = output[0:io_shape_orig[0], 0:io_shape_orig[1], :]  # remove paddind, crop back\r\n",
    "    if probabilities is None:\r\n",
    "        return output[:, :, 1:].astype('bool')\r\n",
    "    else:\r\n",
    "        for i in range(num_classes-1): #don't care about background class\r\n",
    "            output[:,:,i+1] = output[:,:,i+1] > probabilities[i]\r\n",
    "        return output[:, :, 1:].astype('bool')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_path = './segmentation_models/ebc_exp1/Unet__inceptionresnetv2__microscopynet__200__0.981.pth.tar'\r\n",
    "model, preprocessing_fn = load_model(model_path)\r\n",
    "im_path = 'image.tif'\r\n",
    "im = imageio.imread(im_path)\r\n",
    "im = gray2rgb(im)  # convert to color\r\n",
    "im = img_as_ubyte(im)\r\n",
    "\r\n",
    "\r\n",
    "segmentation = segmentation_models_inference(im, model, preprocessing_fn, batch_size=4, patch_size=512,\r\n",
    "                                                     probabilities=None)\r\n",
    "\r\n",
    "for i in segmentation.shape[2]:\r\n",
    "    plt.imshow(segmentation[:,:,i], cmap=plt.cm.gray)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}